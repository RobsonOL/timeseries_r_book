# Modelos de Regressão Dinâmicos

O uso de variáveis explicativas exógenas é uma maneira óbvia de melhorar a precisão das precisões. Em vez de depender apenas de informações históricas sobre a série em si, podemos utilizar outras informações relevantes. 

Modelos de séries temporais como ARIMA permitem que valores da série sejam previstos a partir da inclusão de informações do passado, mas não permitem a inclusão destas variáveis exógenas relevantes como _dummies_ de feriado, atividade dos concorrentes, mudanças nas leis, variáveis macroeconômicas e outras covariadas externas que podem ajudar a explicar a variação histórica de uma série temporal.

Já modelos de regressão permitem a inclusão de variáveis externas, mas não são capazes de modelar as dinâmicas presentes em séries temporais, como os modelos ARIMA são capazes.

### Valor de utilizar variáveis explicativas 

Variáveis externas podem ser especialmente úteis para previsão de demanda por eletricidade, que é altamente dependente da temperatura ambiente, uma vez que dias quentes levam a maior uso de ar condicionados [@taieb2014gradient]. 

Contudo, nem sempre variáveis externas podem ser tão úteis. No caso de temperatura como uma variável explicativa para demanda por eletricidade, as previsões metereológicas podem fornecer medidas bem precisas do comportamento futuro, mas em casos onde as previsões das variáveis explicativas são imprecisas, adiciona-las ao modelo pode produzir resultados inconsistentes. 

Outro problema pode ocorrer caso a relação entre $y$ e $x$ é um fato histórico, mas pode não se repetir no futuro. Ou quando duas variáveis possuem uma relação positiva em um período, e negativa em outro. Esse tipo de problema pode produzir modelos com má especificações e previsões imprecisas. 

Assim, antes de recorrer a variáveis externas em modelos de séries temporais, é sempre interessante iniciar a análise com uma abordagem puramente de séries temporais (um modelo ARIMA, por exemplo). Outra estratégia e a de realizar comparações entre (1) uma previsão para dentro da amostra que inclua variáveis explicativas previstas e (2) uma previsão para dentro da amostra que inclua as mesmas variáveis explicativas com dados observados.


### Modelos Dinâmicos de Regressão

Se existem previsões precisas para as variáveis explicativas e a relação entre estas variáveis e a previsão é estável no futuro, podemos utilizar uma abordagem mista que envolve extender os modelos ARIMA com o objetivo de permitir que outras variáveis externas sejam incluídas nos modelos. Assim, teriamos o melhor dos dois mundos.

Estes modelos de regressão simples tomam a forma 

$$y_t = \beta_0 + \beta_1 x_{1,t} + ... + \beta_k x_{k,t} + \epsilon_t$$


onde $y_t$ é uma função linear das $k$ variáveis externas ($x_{1,t},...,x_{k,t}$), e $\epsilon_t$ é assumido como um termos de erro não correlacionado (ruído branco). Testes como de Breusch-Godfrey foram utilizados para assegurar que os resíduos resultantes da regressão eram significativamente correlacionados.

Neste capítulo, os erros da regressão podem conter autocorrelação. Para enfatizar esta mudança, vamos substituir o uso do $\epsilon_t$ por $\eta_t$. A série de erros $\eta_t$ é assumido como um processo ARIMA. Por exemplo, se $\eta_t$ seguir um processo ARIMA(1,1,1), podemos escrever o modelo como

$$y_t = \beta_0 + \beta_1 x_{1,t} + ... + \beta_k x_{k,t} + \eta_t$$

$$(1-\Phi_1 B)(1-B)\eta_t = (1+ \theta_1 B) \epsilon_t$$

onde $\epsilon_t$ é a série de ruído branco.

Note que o modelo tem dois termos de erro - o erro do modelo de regressão, que denotamos como $\eta_t$. e o termo de erro do modelo ARIMA, que denotamos como $\epsilon_t$. Apenas os erros do modelo ARIMA são assumidos como ruído branco.

## Estimação

Quando estimamos parâmetros do modelo, minimizamos a soma de $\epsilon_t$ ao quadrado. Se minimizarmos a soma de $\eta_t$ ao quadrado (que é o que ocorre quando estimamos um modelo de regressão que ignora a autocorrelação dos erros), então uma série de problemas surgem.

1. Os coeficientes estimados $\hat{\beta}_0,...,\hat{\beta}_k$ não são mais os melhores estimadores, já que algumas informações importantes estão sendo ignoradas no cálculo dos coeficientes.

2. Qualquer teste estatístico associado com o modelo será incorreto.

3. Os valores de AIC dos modelos ajustados não são um bom guia de quão bom é o modelo para previsão.

4. Na maioria dos casos, o p-valor associado com os coeficientes será muito pequeno, e algumas covariadas parecerão importantes quando na verdade não são. Isto produzirá uma regressão espúria.

Minimizar a soma dos $\epsilon_t$ ao quadrado evita estes problemas. Alternativamente, estimação por máxima verossimilhança pode ser utilizada, produzindo estimativas de coeficientes similares.

Uma importante consideração quando estimando um modelo de regressão com erros ARMA é de que todas as variáveis do modelo devem ser estacionárias. Portanto, devemos primeiro checar se $y_t$ é todas as covariadas são estacionárias. Se estimarmos o modelo quando qualquer uma delas é não-estacionária, os coeficientes produzidos não serão consistentes. Uma exceção é quando variáveis não-estacionárias são cointegradas. Se existe uma combinação linear de $y_t$ não-estacionário com um $x_t$ estacionário, então o coeficiente é consistente.

Para tornar as variáveis estacionárias, podemos realizar a transformação de diferenciação, o que produz o chamado "modelo em diferença", em contraste com o "modelo em nível", em os dados originais são utilizados.

Se todas as variáveis são estacionárias, então podemos utilizar erros ARMA para os resíduos. É fácil notar que uma regressão com erros ARIMA é equivalente a uma regressão em diferença com erros ARMA.



## Regressão com Erros ARIMA

A função `Arima()` é capaz de ajustar um modelo de regressão com erros ARIMA se o argumento `xreg` for utilizado. Como a diferenciação está especificada, ela é aplicada para todas as variáveis antes de estimar o modelo. O comando R utilizado é 

```{r eval=F}
library(forecast)
Arima(y, xreg = x, order = c(1,1,0))
```

que irá ajustar um modelo do tipo $y'_t = \beta_1 x'_t + \eta'_t$.


A função `auto.arima()` também é capaz de utilizar covariadas com uso do termo `xreg`. O usuário deve especificar os preditores e `auto.arima()` seleciona o melhor modelo ARIMA para os erros. 

O pacote `modeltime` tem suporte ao modelo ARIMA com o uso da função `arima_reg()` ao se utilizar uma fórmula com regressor externo.


### Exemplo: Consumo e Renda nos EUA

A figura \@ref(fig:consumo-renda) mostra a mudança trimestral nos gastos com consumo pessoal e a renda disponível entre 1970 e 2016. Estamos interessados em prever o consumo com base na renda. Uma mudança na renda não necessariamente reflete uma mudança instântanea no consumo (exempl, depois de uma demissão, pode levar alguns meses para os gastos se ajustarem). Contudo, vamos ignorar esta complexidade e tentar medir o efeito instantâneo de uma mudança média na renda sore uma mudança média nos gastos.

```{r}
us_change_df <- us_change %>% 
  tk_tbl() %>% 
  mutate(Quarter = as.Date(Quarter))

us_change %>% 
  pivot_longer(cols = 2:6) %>% 
  filter(name %in% c("Consumption", "Income")) %>% 
  plot_time_series(Quarter, value, 
                   .facet_vars = name,
                   .facet_scales = "free_y",
                   .smooth = F,
                   .title = "Mudança Percental no Consumo e Renda Trimestral para os EUA, 1970 a 2019")
```

Vamos dividir a base em treinamento e teste para realizar a previsão proposta com a função `initial_time_split()`. Usando o parâmetro `prop = 0.75` fixamos 75% dos dados para a base de treinamento e 25% para a base de teste.

```{r split-consumo, fig.cap="Base de Treinamento e Teste para dados de Consumo"}
tbl_treinamento_teste <- 
  us_change_df %>% 
  initial_time_split(prop = 0.75)

tbl_treinamento_teste %>% 
  tk_time_series_cv_plan() %>% 
  plot_time_series_cv_plan(Quarter, 
                           Consumption,
                           .title = "Base de Treinamento e Teste")
```



Seguindo o fluxo de trabalho do pacote `tidymodels`, começamos criando o modelo com a função `arima_reg()` e a conectamos à função `forecast::auto.arima()` usando a expressão `set_engine("auto_arima")`. Com o pacote `recipe` podemos definir uma fórmula que toma `Consumption` como variável dependente e `Income` como um regressor. Com a função `workflow` unimos modelo e fórmula para realizar o ajuste do modelo.

```{r message=FALSE, warning=FALSE}
modelo_regarima <- arima_reg() %>% 
  set_engine("auto_arima")

receita <- recipe(Consumption ~ Quarter + Income, training(tbl_treinamento_teste))
fit <- workflow() %>% 
  add_model(modelo_regarima) %>% 
  add_recipe(receita) %>% 
  fit(training(tbl_treinamento_teste))
```
Abaixo temos a saída do ajuste do modelo que foi ajustado para a base de treinamento.

```{r}
fit
```


Os dados são claramente estacionários (já que estamos considerando mudanças percentuais em vez de gastos e renda bruta), de modo que não há necessidade de diferenciação. O modelo ajustado é

$$y_t = 0.6180 + 0.2725x_t + \eta_t$$
$$\eta_t = 0.5987 \eta_{t-1} + \epsilon_t - 0.5570\epsilon_{t-1} + 0.1840 \epsilon_{t-2}$$

$$\epsilon \sim IID(0, 0.3545)$$

Podemos recuperar as estimativas de $\eta_t$ e $\epsilon_t$ usando a função `residuals()`. A figura \@ref(fig:erros-arima) mostra que os resíduos do modelo parecem bem comportados, lembrando um processo de ruído branco.

```{r erros-arima, fig.cap="Resíduos de Regressão e Resíduos ARIMA para o modelo ajustado", message=FALSE, warning=FALSE}
tbl_calibracao <- 
  modeltime_calibrate(fit, 
                      new_data = testing(tbl_treinamento_teste))
  
  
tbl_calibracao %>% 
  modeltime_residuals() %>%  
  plot_modeltime_residuals(.title = "Resíduos do Modelo de Regressão com Erros ARIMA", 
                           .legend_show = F)

```

Na figura \@ref(fig:erros-arima-acf) vemos o correlograma dos resíduos. As barras azuis indicam que as autocorrelações são indistinguíveis de um ruído branco.

```{r erros-arima-acf, fig.cap="ACF dos Resíduos de Regressão e Resíduos ARIMA para o modelo ajustado", message=FALSE, warning=FALSE}


tbl_calibracao %>% 
  modeltime_residuals() %>% 
  plot_modeltime_residuals(.type = "acf", .lag = 40,
    .title = "ACF dos Resíduos do Modelo de Regressão com Erros ARIMA", 
    .show_white_noise_bar = T)

```

O teste de Ljung-Box, ACF e histograma parecem confirmar as informações do ACF, e indicam que os resíduos não são significativamente diferentes de um ruído branco.

A tabela \@ref(tab:tab-residuos-regarima) mostra o resultado para testes de normalidade e de autocorrelação dos resíduos. O teste de Shapiro-Wilk indica que os resíduos parecem normais. Os testes de Ljung-Box e Box-Pierce mostram que os resíduos não são significativamente diferentes de um ruído branco.

```{r tab-residuos-regarima}
tbl_calibracao %>% 
  modeltime_residuals() %>% 
  modeltime_residuals_test() %>% 
  select(-.model_id, -.model_desc) %>% 
  knitr::kable(caption = "Testes para Resíduos do Modelo de Regressão com Erros ARIMA")

```


## Previsão

A figura \@ref(fig:forecast-regarima) mostra a previsão feita para o período de teste. A linha azul mostra os dados reais e a linha vermelha, a previsão produzida pelo modelo.

```{r forecast-regarima, fig.cap = "Previsão de Consumo do Modelo de Regressão com Erros ARIMA"}
tbl_calibracao %>% 
  modeltime_forecast(new_data = testing(tbl_treinamento_teste),
                     actual_data = us_change_df) %>% 
  plot_modeltime_forecast(.legend_show = F)
```
É importante destacar que a previsão de valores futuros envolve a previsão de valores futuros para os preditores. O intervalo de confiança produzido pela previsão não leva em consideração a incerteza adicional de ter que prever valores para os preditores, e assim devem ser interpretado como condicional aos valores assumidos. 
 
Para finalizar, podemos calcular algumas medidas de performance. Os resultados são exibidos na tabela \@ref(tab:tab-medidas-regarima).

```{r tab-medidas-regarima}
tbl_calibracao %>% 
  modeltime_accuracy(new_data = testing(tbl_treinamento_teste)) %>% 
  select(-.model_id, -.model_desc, -.type) %>% 
  knitr::kable(caption = "Medidas de Performance do Modelo de Regressão com Erros ARIMA")
```

Considerando que os dados de mudança percentual do consumo estão ao redor de zero, não é surpreendente que o valor calculado para o MAPE esteja tão elevado.


## Exemplo 2: Previsão de Demanda por Eletricidade

```{r eletricidade-diaria, fig.cap = "Demanda por Eletricidade diária e temperatura máxima apara o Estado de Vitoria na Australia, 2014"}
vic_elec_daily <- vic_elec %>% 
  tk_tbl() %>% 
  filter(year(Time) == 2014) %>% 
  group_by(Date) %>% 
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) %>% 
  mutate(Day_Type = case_when(
    Holiday ~ "Feriado",
    wday(Date) %in% 2:6 ~ "Fim-de-semana",
    TRUE ~ "Dia-de-semana"
  ))

vic_elec_daily %>% 
  pivot_longer(c(Demand, Temperature)) %>% 
  plot_time_series(Date, value,
                   .facet_vars = name,
                   .title = "",
                   .smooth = F)
  
```

A figura \@ref(fig:energia-temp) mostra que existe uma relação não linear entre temperatura e demanda por eletricidade. Essa relação se altera a depender do tipo de dia: durante os fins de semana, a demanda por eletricidade é maior, mesmo quando controlamos por temperatura.

```{r energia-temp, fig.cap = "Relação entre demanda diária por eletricidade e temperatura para o Estado de Vitória na Australia, 2014}
vic_elec_daily %>% 
  ggplot(aes(x = Temperature, y = Demand, colour = Day_Type)) +
  geom_point() + 
  labs(y = "Demanda por Eletricidade (GW)",
       x = "Temperatura Máxima",
       color = "Dia da Semana")
```


```{r}
elec_splits <- vic_elec_daily %>% 
  initial_time_split(prop = 0.75)

elec_splits %>% 
    tk_time_series_cv_plan() %>% 
  plot_time_series_cv_plan(Date, 
                           Demand,
                           .title = "Base de Treinamento e Teste")


```


```{r}


receita_elec <- recipe(Demand ~ ., data = training(elec_splits)) %>% 
  step_rm(Holiday) %>% 
  step_dummy(Day_Type) %>% 
  step_poly(Temperature)

receita_elec %>% prep() %>% bake(new_data = NULL)
  
```
```{r}

fit_elec <- workflow() %>% 
  add_model(modelo_regarima) %>% 
  add_recipe(receita_elec) %>% 
  fit(training(elec_splits))

fit_elec
```

```{r message=FALSE, warning=FALSE}
tbl_calibracao_elec <- fit_elec %>% 
  modeltime_calibrate(new_data = testing(elec_splits))


tbl_calibracao_elec %>% 
  modeltime_residuals() %>% 
  plot_modeltime_residuals(.type = "acf", .show_white_noise_bar = T, .lag = 21)
```

```{r}
tbl_calibracao_elec %>% 
  modeltime_forecast(new_data = testing(elec_splits),
                     actual_data = vic_elec_daily) %>% 
  plot_modeltime_forecast(.legend_max_width = 10)
```

```{r}

```


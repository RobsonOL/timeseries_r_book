[["arimax.html", "Capítulo 9 Modelos de Regressão Dinâmicos 9.1 Estimação 9.2 Regressão com Erros ARIMA 9.3 Previsão 9.4 Exemplo 2: Previsão de Demanda por Eletricidade", " Capítulo 9 Modelos de Regressão Dinâmicos O uso de variáveis explicativas exógenas é uma maneira óbvia de melhorar a precisão das precisões. Em vez de depender apenas de informações históricas sobre a série em si, podemos utilizar outras informações relevantes. Modelos de séries temporais como ARIMA permitem que valores da série sejam previstos a partir da inclusão de informações do passado, mas não permitem a inclusão destas variáveis exógenas relevantes como dummies de feriado, atividade dos concorrentes, mudanças nas leis, variáveis macroeconômicas e outras covariadas externas que podem ajudar a explicar a variação histórica de uma série temporal. Já modelos de regressão permitem a inclusão de variáveis externas, mas não são capazes de modelar as dinâmicas presentes em séries temporais, como os modelos ARIMA são capazes. 9.0.1 Valor de utilizar variáveis explicativas Variáveis externas podem ser especialmente úteis para previsão de demanda por eletricidade, que é altamente dependente da temperatura ambiente, uma vez que dias quentes levam a maior uso de ar condicionados (Taieb and Hyndman 2014). Contudo, nem sempre variáveis externas podem ser tão úteis. No caso de temperatura como uma variável explicativa para demanda por eletricidade, as previsões metereológicas podem fornecer medidas bem precisas do comportamento futuro, mas em casos onde as previsões das variáveis explicativas são imprecisas, adiciona-las ao modelo pode produzir resultados inconsistentes. Outro problema pode ocorrer caso a relação entre \\(y\\) e \\(x\\) é um fato histórico, mas pode não se repetir no futuro. Ou quando duas variáveis possuem uma relação positiva em um período, e negativa em outro. Esse tipo de problema pode produzir modelos com má especificações e previsões imprecisas. Assim, antes de recorrer a variáveis externas em modelos de séries temporais, é sempre interessante iniciar a análise com uma abordagem puramente de séries temporais (um modelo ARIMA, por exemplo). Outra estratégia e a de realizar comparações entre (1) uma previsão para dentro da amostra que inclua variáveis explicativas previstas e (2) uma previsão para dentro da amostra que inclua as mesmas variáveis explicativas com dados observados. 9.0.2 Modelos Dinâmicos de Regressão Se existem previsões precisas para as variáveis explicativas e a relação entre estas variáveis e a previsão é estável no futuro, podemos utilizar uma abordagem mista que envolve extender os modelos ARIMA com o objetivo de permitir que outras variáveis externas sejam incluídas nos modelos. Assim, teriamos o melhor dos dois mundos. Estes modelos de regressão simples tomam a forma \\[y_t = \\beta_0 + \\beta_1 x_{1,t} + ... + \\beta_k x_{k,t} + \\epsilon_t\\] onde \\(y_t\\) é uma função linear das \\(k\\) variáveis externas (\\(x_{1,t},...,x_{k,t}\\)), e \\(\\epsilon_t\\) é assumido como um termos de erro não correlacionado (ruído branco). Testes como de Breusch-Godfrey foram utilizados para assegurar que os resíduos resultantes da regressão eram significativamente correlacionados. Neste capítulo, os erros da regressão podem conter autocorrelação. Para enfatizar esta mudança, vamos substituir o uso do \\(\\epsilon_t\\) por \\(\\eta_t\\). A série de erros \\(\\eta_t\\) é assumido como um processo ARIMA. Por exemplo, se \\(\\eta_t\\) seguir um processo ARIMA(1,1,1), podemos escrever o modelo como \\[y_t = \\beta_0 + \\beta_1 x_{1,t} + ... + \\beta_k x_{k,t} + \\eta_t\\] \\[(1-\\Phi_1 B)(1-B)\\eta_t = (1+ \\theta_1 B) \\epsilon_t\\] onde \\(\\epsilon_t\\) é a série de ruído branco. Note que o modelo tem dois termos de erro - o erro do modelo de regressão, que denotamos como \\(\\eta_t\\). e o termo de erro do modelo ARIMA, que denotamos como \\(\\epsilon_t\\). Apenas os erros do modelo ARIMA são assumidos como ruído branco. 9.1 Estimação Quando estimamos parâmetros do modelo, minimizamos a soma de \\(\\epsilon_t\\) ao quadrado. Se minimizarmos a soma de \\(\\eta_t\\) ao quadrado (que é o que ocorre quando estimamos um modelo de regressão que ignora a autocorrelação dos erros), então uma série de problemas surgem. Os coeficientes estimados \\(\\hat{\\beta}_0,...,\\hat{\\beta}_k\\) não são mais os melhores estimadores, já que algumas informações importantes estão sendo ignoradas no cálculo dos coeficientes. Qualquer teste estatístico associado com o modelo será incorreto. Os valores de AIC dos modelos ajustados não são um bom guia de quão bom é o modelo para previsão. Na maioria dos casos, o p-valor associado com os coeficientes será muito pequeno, e algumas covariadas parecerão importantes quando na verdade não são. Isto produzirá uma regressão espúria. Minimizar a soma dos \\(\\epsilon_t\\) ao quadrado evita estes problemas. Alternativamente, estimação por máxima verossimilhança pode ser utilizada, produzindo estimativas de coeficientes similares. Uma importante consideração quando estimando um modelo de regressão com erros ARMA é de que todas as variáveis do modelo devem ser estacionárias. Portanto, devemos primeiro checar se \\(y_t\\) é todas as covariadas são estacionárias. Se estimarmos o modelo quando qualquer uma delas é não-estacionária, os coeficientes produzidos não serão consistentes. Uma exceção é quando variáveis não-estacionárias são cointegradas. Se existe uma combinação linear de \\(y_t\\) não-estacionário com um \\(x_t\\) estacionário, então o coeficiente é consistente. Para tornar as variáveis estacionárias, podemos realizar a transformação de diferenciação, o que produz o chamado modelo em diferença, em contraste com o modelo em nível, em os dados originais são utilizados. Se todas as variáveis são estacionárias, então podemos utilizar erros ARMA para os resíduos. É fácil notar que uma regressão com erros ARIMA é equivalente a uma regressão em diferença com erros ARMA. 9.2 Regressão com Erros ARIMA A função Arima() é capaz de ajustar um modelo de regressão com erros ARIMA se o argumento xreg for utilizado. Como a diferenciação está especificada, ela é aplicada para todas as variáveis antes de estimar o modelo. O comando R utilizado é library(forecast) Arima(y, xreg = x, order = c(1,1,0)) que irá ajustar um modelo do tipo \\(y&#39;_t = \\beta_1 x&#39;_t + \\eta&#39;_t\\). A função auto.arima() também é capaz de utilizar covariadas com uso do termo xreg. O usuário deve especificar os preditores e auto.arima() seleciona o melhor modelo ARIMA para os erros. O pacote modeltime tem suporte ao modelo ARIMA com o uso da função arima_reg() ao se utilizar uma fórmula com regressor externo. 9.2.1 Exemplo: Consumo e Renda nos EUA A figura ?? mostra a mudança trimestral nos gastos com consumo pessoal e a renda disponível entre 1970 e 2016. Estamos interessados em prever o consumo com base na renda. Uma mudança na renda não necessariamente reflete uma mudança instântanea no consumo (exempl, depois de uma demissão, pode levar alguns meses para os gastos se ajustarem). Contudo, vamos ignorar esta complexidade e tentar medir o efeito instantâneo de uma mudança média na renda sore uma mudança média nos gastos. us_change_df &lt;- us_change %&gt;% tk_tbl() %&gt;% mutate(Quarter = as.Date(Quarter)) ## Warning in tk_tbl.data.frame(.): Warning: No index to preserve. Object otherwise converted to tibble successfully. us_change %&gt;% pivot_longer(cols = 2:6) %&gt;% filter(name %in% c(&quot;Consumption&quot;, &quot;Income&quot;)) %&gt;% plot_time_series(Quarter, value, .facet_vars = name, .facet_scales = &quot;free_y&quot;, .smooth = F, .title = &quot;Mudança Percental no Consumo e Renda Trimestral para os EUA, 1970 a 2019&quot;) Vamos dividir a base em treinamento e teste para realizar a previsão proposta com a função initial_time_split(). Usando o parâmetro prop = 0.75 fixamos 75% dos dados para a base de treinamento e 25% para a base de teste. tbl_treinamento_teste &lt;- us_change_df %&gt;% initial_time_split(prop = 0.75) tbl_treinamento_teste %&gt;% tk_time_series_cv_plan() %&gt;% plot_time_series_cv_plan(Quarter, Consumption, .title = &quot;Base de Treinamento e Teste&quot;) Figure 9.1: Base de Treinamento e Teste para dados de Consumo Seguindo o fluxo de trabalho do pacote tidymodels, começamos criando o modelo com a função arima_reg() e a conectamos à função forecast::auto.arima() usando a expressão set_engine(\"auto_arima\"). Com o pacote recipe podemos definir uma fórmula que toma Consumption como variável dependente e Income como um regressor. Com a função workflow unimos modelo e fórmula para realizar o ajuste do modelo. modelo_regarima &lt;- arima_reg() %&gt;% set_engine(&quot;auto_arima&quot;) receita &lt;- recipe(Consumption ~ Quarter + Income, training(tbl_treinamento_teste)) fit &lt;- workflow() %&gt;% add_model(modelo_regarima) %&gt;% add_recipe(receita) %&gt;% fit(training(tbl_treinamento_teste)) Abaixo temos a saída do ajuste do modelo que foi ajustado para a base de treinamento. fit ## == Workflow [trained] ============================================================================================ ## Preprocessor: Recipe ## Model: arima_reg() ## ## -- Preprocessor -------------------------------------------------------------------------------------------------- ## 0 Recipe Steps ## ## -- Model --------------------------------------------------------------------------------------------------------- ## Series: outcome ## Regression with ARIMA(1,0,2) errors ## ## Coefficients: ## ar1 ma1 ma2 intercept income ## 0.5987 -0.5570 0.1840 0.6180 0.2725 ## s.e. 0.1945 0.2016 0.0821 0.0886 0.0608 ## ## sigma^2 estimated as 0.3545: log likelihood=-130.8 ## AIC=273.59 AICc=274.19 BIC=291.58 Os dados são claramente estacionários (já que estamos considerando mudanças percentuais em vez de gastos e renda bruta), de modo que não há necessidade de diferenciação. O modelo ajustado é \\[y_t = 0.6180 + 0.2725x_t + \\eta_t\\] \\[\\eta_t = 0.5987 \\eta_{t-1} + \\epsilon_t - 0.5570\\epsilon_{t-1} + 0.1840 \\epsilon_{t-2}\\] \\[\\epsilon \\sim IID(0, 0.3545)\\] Podemos recuperar as estimativas de \\(\\eta_t\\) e \\(\\epsilon_t\\) usando a função residuals(). A figura 9.2 mostra que os resíduos do modelo parecem bem comportados, lembrando um processo de ruído branco. tbl_calibracao &lt;- modeltime_calibrate(fit, new_data = testing(tbl_treinamento_teste)) tbl_calibracao %&gt;% modeltime_residuals() %&gt;% plot_modeltime_residuals(.title = &quot;Resíduos do Modelo de Regressão com Erros ARIMA&quot;, .legend_show = F) Figure 9.2: Resíduos de Regressão e Resíduos ARIMA para o modelo ajustado Na figura 9.3 vemos o correlograma dos resíduos. As barras azuis indicam que as autocorrelações são indistinguíveis de um ruído branco. tbl_calibracao %&gt;% modeltime_residuals() %&gt;% plot_modeltime_residuals(.type = &quot;acf&quot;, .lag = 40, .title = &quot;ACF dos Resíduos do Modelo de Regressão com Erros ARIMA&quot;, .show_white_noise_bar = T) Figure 9.3: ACF dos Resíduos de Regressão e Resíduos ARIMA para o modelo ajustado O teste de Ljung-Box, ACF e histograma parecem confirmar as informações do ACF, e indicam que os resíduos não são significativamente diferentes de um ruído branco. A tabela 9.1 mostra o resultado para testes de normalidade e de autocorrelação dos resíduos. O teste de Shapiro-Wilk indica que os resíduos parecem normais. Os testes de Ljung-Box e Box-Pierce mostram que os resíduos não são significativamente diferentes de um ruído branco. tbl_calibracao %&gt;% modeltime_residuals() %&gt;% modeltime_residuals_test() %&gt;% select(-.model_id, -.model_desc) %&gt;% knitr::kable(caption = &quot;Testes para Resíduos do Modelo de Regressão com Erros ARIMA&quot;) Table 9.1: Testes para Resíduos do Modelo de Regressão com Erros ARIMA shapiro_wilk box_pierce ljung_box durbin_watson 0.1814417 0.8089019 0.8032553 1.326655 9.3 Previsão A figura 9.4 mostra a previsão feita para o período de teste. A linha azul mostra os dados reais e a linha vermelha, a previsão produzida pelo modelo. tbl_calibracao %&gt;% modeltime_forecast(new_data = testing(tbl_treinamento_teste), actual_data = us_change_df) %&gt;% plot_modeltime_forecast(.legend_show = F) Figure 9.4: Previsão de Consumo do Modelo de Regressão com Erros ARIMA É importante destacar que a previsão de valores futuros envolve a previsão de valores futuros para os preditores. O intervalo de confiança produzido pela previsão não leva em consideração a incerteza adicional de ter que prever valores para os preditores, e assim devem ser interpretado como condicional aos valores assumidos. Para finalizar, podemos calcular algumas medidas de performance. Os resultados são exibidos na tabela 9.2. tbl_calibracao %&gt;% modeltime_accuracy(new_data = testing(tbl_treinamento_teste)) %&gt;% select(-.model_id, -.model_desc, -.type) %&gt;% knitr::kable(caption = &quot;Medidas de Performance do Modelo de Regressão com Erros ARIMA&quot;) Table 9.2: Medidas de Performance do Modelo de Regressão com Erros ARIMA mae mape mase smape rmse rsq 0.4186742 138.5321 1.232955 72.59967 0.5516429 0.0666645 Considerando que os dados de mudança percentual do consumo estão ao redor de zero, não é surpreendente que o valor calculado para o MAPE esteja tão elevado. 9.4 Exemplo 2: Previsão de Demanda por Eletricidade vic_elec_daily &lt;- vic_elec %&gt;% tk_tbl() %&gt;% filter(year(Time) == 2014) %&gt;% group_by(Date) %&gt;% summarise( Demand = sum(Demand) / 1e3, Temperature = max(Temperature), Holiday = any(Holiday) ) %&gt;% mutate(Day_Type = case_when( Holiday ~ &quot;Feriado&quot;, wday(Date) %in% 2:6 ~ &quot;Fim-de-semana&quot;, TRUE ~ &quot;Dia-de-semana&quot; )) ## Warning in tk_tbl.data.frame(.): Warning: No index to preserve. Object otherwise converted to tibble successfully. vic_elec_daily %&gt;% pivot_longer(c(Demand, Temperature)) %&gt;% plot_time_series(Date, value, .facet_vars = name, .title = &quot;&quot;, .smooth = F) Figure 9.5: Demanda por Eletricidade diária e temperatura máxima apara o Estado de Vitoria na Australia, 2014 A figura 9.6 mostra que existe uma relação não linear entre temperatura e demanda por eletricidade. Essa relação se altera a depender do tipo de dia: durante os fins de semana, a demanda por eletricidade é maior, mesmo quando controlamos por temperatura. vic_elec_daily %&gt;% ggplot(aes(x = Temperature, y = Demand, colour = Day_Type)) + geom_point() + labs(y = &quot;Demanda por Eletricidade (GW)&quot;, x = &quot;Temperatura Máxima&quot;, color = &quot;Dia da Semana&quot;) Figure 9.6: Relação entre demanda diária por eletricidade e temperatura para o Estado de Vitória na Australia, 2014 elec_splits &lt;- vic_elec_daily %&gt;% initial_time_split(prop = 0.75) elec_splits %&gt;% tk_time_series_cv_plan() %&gt;% plot_time_series_cv_plan(Date, Demand, .title = &quot;Base de Treinamento e Teste&quot;) receita_elec &lt;- recipe(Demand ~ ., data = training(elec_splits)) %&gt;% step_rm(Holiday) %&gt;% step_dummy(Day_Type) %&gt;% step_poly(Temperature) receita_elec %&gt;% prep() %&gt;% bake(new_data = NULL) ## # A tibble: 273 x 6 ## Date Demand Day_Type_Feriado Day_Type_Fim.de.semana Temperature_poly_1 Temperature_poly_2 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2014-01-01 175. 1 0 0.0519 -0.0544 ## 2 2014-01-02 188. 0 1 0.0234 -0.0547 ## 3 2014-01-03 189. 0 1 0.0159 -0.0517 ## 4 2014-01-04 174. 0 0 -0.00212 -0.0393 ## 5 2014-01-05 170. 0 0 0.0528 -0.0541 ## 6 2014-01-06 195. 0 1 -0.00875 -0.0330 ## 7 2014-01-07 200. 0 1 -0.00496 -0.0367 ## 8 2014-01-08 205. 0 1 0.0651 -0.0481 ## 9 2014-01-09 227. 0 1 0.112 0.00669 ## 10 2014-01-10 258. 0 1 0.128 0.0349 ## # ... with 263 more rows fit_elec &lt;- workflow() %&gt;% add_model(modelo_regarima) %&gt;% add_recipe(receita_elec) %&gt;% fit(training(elec_splits)) ## frequency = 7 observations per 1 week fit_elec ## == Workflow [trained] ============================================================================================ ## Preprocessor: Recipe ## Model: arima_reg() ## ## -- Preprocessor -------------------------------------------------------------------------------------------------- ## 3 Recipe Steps ## ## * step_rm() ## * step_dummy() ## * step_poly() ## ## -- Model --------------------------------------------------------------------------------------------------------- ## Series: outcome ## Regression with ARIMA(2,0,1)(0,0,2)[7] errors ## ## Coefficients: ## ar1 ar2 ma1 sma1 sma2 intercept day_type_feriado day_type_fim_de_semana ## 1.2865 -0.3586 -0.4817 0.1527 0.3246 200.1825 3.6693 33.3701 ## s.e. 0.6723 0.5746 0.6511 0.0690 0.0579 4.2842 2.1880 1.2064 ## temperature_poly_1 temperature_poly_2 ## 149.4592 186.9024 ## s.e. 11.8570 9.4430 ## ## sigma^2 estimated as 45.8: log likelihood=-905.87 ## AIC=1833.73 AICc=1834.74 BIC=1873.44 tbl_calibracao_elec &lt;- fit_elec %&gt;% modeltime_calibrate(new_data = testing(elec_splits)) tbl_calibracao_elec %&gt;% modeltime_residuals() %&gt;% plot_modeltime_residuals(.type = &quot;acf&quot;, .show_white_noise_bar = T, .lag = 21) tbl_calibracao_elec %&gt;% modeltime_forecast(new_data = testing(elec_splits), actual_data = vic_elec_daily) %&gt;% plot_modeltime_forecast(.legend_max_width = 10) tbl_calibracao_elec ## # Modeltime Table ## # A tibble: 1 x 5 ## .model_id .model .model_desc .type .calibration_data ## &lt;int&gt; &lt;list&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 1 &lt;workflow&gt; REGRESSION WITH ARIMA(2,0,1)(0,0,2)[7] ERRORS Test &lt;tibble [92 x 4]&gt; References "]]

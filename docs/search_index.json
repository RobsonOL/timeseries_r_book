[["index.html", "Séries Temporais com R Capítulo 1 Prefácio 1.1 Roteiro 1.2 Pré-requisitos", " Séries Temporais com R Robson Oliveira Lima 2021-12-10 Capítulo 1 Prefácio Este é um livro online que fornece uma breve introdução aos principais métodos de previsão em séries temporais. R é uma linguagem de programação gratuita e bastante popular para análise estatística. Este livro é uma tentativa de traduzir o livro online Forecasting: Principles and Practice, que é uma das principais referências para o ensino de previsão com R. Ao mesmo tempo, muito dos exemplos serão adaptados para utilizar os pacotes timetk (Dancho and Vaughan 2021) e modetime (Dancho 2021). Estes dois pacotes tornam a tarefa de realizar previsão muito conveniente. 1.1 Roteiro bla bla 1.2 Pré-requisitos bla bla References "],["os-fundamentos-de-séries-temporais.html", "Capítulo 2 Os fundamentos de séries temporais 2.1 O que pode ser previsto? 2.2 Principais modelos de previsão 2.3 O passo-a-passo de realizar uma previsão 2.4 Um Projeto de Previsão de Ponta a Ponta", " Capítulo 2 Os fundamentos de séries temporais 2.1 O que pode ser previsto? 2.2 Principais modelos de previsão 2.3 O passo-a-passo de realizar uma previsão 2.4 Um Projeto de Previsão de Ponta a Ponta "],["ts.html", "Capítulo 3 Séries Temporais 3.1 Características de Séries Temporais 3.2 Objeto ts 3.3 Gráficos de Séries Temporais 3.4 Padrões das Séries Temporais", " Capítulo 3 Séries Temporais Aqui vamos explorar o que é uma série temporal, suas principais características. 3.1 Características de Séries Temporais Séries temporais se referem a dados observados em diferentes pontos no tempo. O uso de métodos estatísticos convencionais como o de regressão linear dependem e suposições de que as observações são independentes entre si, uma hipótese que não faz sentido quando se trabalha com observações no tempo: cada observação está correlacionada com as observações mais próximas no tempo. Assim, um choque no valor da ação que ocorre ontem tem efeitos no preço da ação hoje. Na economia observamos a taxa semanal de juros, o preço de fechamento das ações, o índice de preço mensal, as vendas anuais, e por ai vai. Em meteorologia, observamos as temperaturas médias diárias, a precipitação anual, índices de seca e outros. Na agricultura temos o registro anual da colheita e da produção de leite, erosão do solo e valor das exportações. A lista de áreas em que séries temporais podem ser estudadas não tem fim. O objetivo da análise de séries temporais são de: (1) entender ou modelar os mecanismos que produzem a série observada e (2) prever valores futuros de uma série com base na história da série, e quando possível, com relação a outras séries ou fatores. 3.2 Objeto ts Uma série temporal pode ser representada como uma lista de números em sequência, onde cada número é uma informação sobre um período específico de tempo. No R, essas informações podem ser registradas como objetos ts. A tabela 3.1 mostra um exemplo de dados anuais para o período entre 2012 e 2016. Table 3.1: Informações no Tempo Ano Observações 2012 123 2013 39 2014 78 2015 52 2016 110 Podemos transformar as informações acima em um objeto ts utilizando a função ts(): y &lt;- ts(c(123,39,78,52,110), start = 2012) y ## Time Series: ## Start = 2012 ## End = 2016 ## Frequency = 1 ## [1] 123 39 78 52 110 Se seus dados são anuais, com uma observação por ano, você precisa apenas fornecer o ano inicio (ou o ano final). Para observações que são mais frequentes que uma vez ao ano, é preciso fornecer um argumento de frequência (frequency). Por exemplo, se seus dados são mensais, então ele pode ser convertido para um objeto ts da seguinte maneira: dados_mensais &lt;- c(10, 30, 50, 70, 90) y &lt;- ts(dados_mensais, start = 2015, frequency = 12) y ## Jan Feb Mar Apr May ## 2015 10 30 50 70 90 3.2.1 Frequências de uma série temporal A frequência é o número de observações antes que o padrão sazonal se repita. Quando usamos a função ts no R, podemos utilizar as seguintes frequências: Table 3.2: Frequências de uma Série Temporal Dados Frequência Anual 1 Trimestral 4 Mensal 12 Semanal 52 Em relação ao padrão semanal, na verdade temos \\(365.25/7 = 52.18\\) semanas em média em um ano, e não 52 semanas. Contudo, a maioria das funções que utilizam a função ts exigem que a frequency seja fornecida como um número inteiro. Se a frequência de observações é maior do que uma vez por semana, existem algumas formas de lidar com a situação. Por exemplo, dados diários podem ter um padrão de sazonalidade semanal (frequency = 7) ou uma sazonalidade anual (frequency = 365.25). De modo similar, dados que são observados por minuto, podem ter um padrão sazonal a cada hora (frequency = 60), uma sazonalidade diária (frequency = 1440, ou \\(24 \\times 60\\)), uma sazonalidade semanal (frequency = 10080, ou \\(24 \\times 60 \\times 7\\)) e anual (frequency = 525960, ou \\(24 \\times 60 \\times 365.25\\)). Para utilizar um objeto ts nestes casos, é preciso decidir que desses padrões sazonais é mais importante. Contudo, o R permite lidar com dados com múltiplas sazonalidades utilizando técnicas mais avançadas. 3.3 Gráficos de Séries Temporais Para séries temporais, o gráfico apropriado mostra as observações no tempo, com observações consecutivas sendo unidas por uma linha reta. A figura 3.1 mostra um exemplo de um gráfico de séries temporais. library(fpp) library(tidyverse) autoplot(melsyd[,&quot;Economy.Class&quot;]) + ggtitle(&quot;Passageiros da Classe Econômica: Melborne-Sydney&quot;) + xlab(&quot;Ano&quot;) + ylab(&quot;Milhares&quot;) Figure 3.1: Total de passageiros semanais na Compainha Áerea Ansett Os dados fazem parte do pacote fpp, que acompanha o livro Forecasting: Principles and Practice. Com a função autoplot(), produzimos gráficos no tempo a partir de objetos ts. Alternativamente podemos transformar o objeto ts em um data.frame: dados_passageiros &lt;- data.frame(passageiros_economicos = as.matrix(melsyd[,&quot;Economy.Class&quot;]), date = time(melsyd)) dados_passageiros %&gt;% head() %&gt;% knitr::kable() passageiros_economicos date 20.167 1987.481 20.161 1987.500 19.993 1987.519 20.986 1987.538 20.497 1987.558 20.770 1987.577 A partir do objeto dados_passageiros é possível produzir o mesmo gráfico utilizando o pacote ggplot2 (figura 3.2). dados_passageiros %&gt;% ggplot(aes(y = passageiros_economicos, x = date)) + geom_line() + labs(y = &quot;Milhares&quot;, x = &quot;Ano&quot;, title = &quot;Passageiros da Classe Econômica: Melborne-Sydney&quot;) Figure 3.2: Total de passageiros semanais na Compainha Áerea Ansett Independemente da forma como o gráfico é produzido, ele revela algumas características interessantes: Em 1989 nenhum passageiro foi transportado. Durante 1992 houve um período de redução de passageiros. Um grande aumento no número de passageiros transportados em 1991. Inícios de ano sempre produzem aumentos no numero de passageiros em razão do efeito das festas de fim de ano. Existe uma flutuação de longo prazo, em que o nível de passageiros é elevado no início da série, diminui em 1989, e volta a aumentar novamente entre 1990 e 1991. Existem alguns períodos sem informação. Para realizar previsão dessa série, todas essas características precisam ser levadas em conta. 3.3.1 Convertendo tk para data.frame O pacote timetk possui uma série de funções convenientes para converter objetos ts para outros formatos. A função tk_tbl converte o objeto ts para um objeto tibble (objeto equivalente a um dataframe). Já a função tk_ts faz o caminho inverso. library(timetk) melsyd %&gt;% # converte ts em tibble tk_tbl() %&gt;% mutate(index = as.Date(index)) %&gt;% tail() %&gt;% knitr::kable() index First.Class Business.Class Economy.Class 1975-06-16 1.417 3.152 27.322 1975-06-16 1.458 3.053 28.837 1975-06-16 1.398 2.745 26.548 1975-06-16 1.423 3.156 27.279 1975-06-16 1.358 3.069 27.306 1975-06-16 1.488 3.379 28.299 3.4 Padrões das Séries Temporais Ao descrever séries temporais, usamos palavras como tendência, sazonalidade e padrão cíclico. Antes disso, podemos observar uma série sem padrão definido. 3.4.1 Série sem padrão Na figura 3.3 vemos a média de precipitação na cidade americana de Los Angelos durante o período de 1878 a 1992. Estes dados estão no pacote TSA, que acompanha o livro Time Series Analysis. library(TSA) data(larain) larain &lt;- data.frame(chuva_anual = as.matrix(larain), date = time(larain)) larain %&gt;% ggplot(aes(x = date, y = chuva_anual)) + geom_line() + geom_point() + labs(x = &quot;&quot;, y = &quot;Precipitação em polegadas&quot;, title = &quot;Chuva Anual em Los Angeles, 1878 - 1992&quot;, subtitle = &quot;Em polegadas de Chuva por Ano&quot;) Figure 3.3: Padrão de Chuvas em Los Angeles É possível perceber uma variação no volume chuvas ao longo dos anos  alguns anos com um volume de chuva mais alto, outros mais baixo. Estamos interessados se os valores da chuva estão relacionados entre si. Será que ao conhecer o comportamento da chuva em um conjunto de anos podemos prever o que ocorrerá em anos consecutivos? Podemos criar uma variável relativa a chuva do ano anterior e compara-la com a chuva no ano corrente. A tabela 3.3 mostra essa comparação. larain &lt;- larain %&gt;% mutate(chuva_ano_anterior = lag(chuva_anual)) larain %&gt;% head() %&gt;% knitr::kable(caption = &quot;Volume Anual de Chuvas em Los Angeles&quot;) Table 3.3: Volume Anual de Chuvas em Los Angeles chuva_anual date chuva_ano_anterior 20.86 1878 NA 17.41 1879 20.86 18.65 1880 17.41 5.53 1881 18.65 10.74 1882 5.53 14.14 1883 10.74 Assim, em 1877 observamos 17,41 polegadas de chuva, e a chuva do ano anterior somou 20,86 polegadsa de chuva. Na figura 3.4 exibimos as duas informações lado a lado com um gráfico de dispersão. larain %&gt;% ggplot(aes(x = chuva_anual, y = chuva_ano_anterior)) + geom_point() + geom_smooth() + labs(x = &quot;Chuva anual&quot;, y = &quot;Volume de chuva do ano anterior&quot;, title = &quot;Volume de Chuva em Los Angeles, 1876 - 1992&quot;, subtitle = &quot;Relação entre a Chuva Anual e o Volume de Chuva no Ano Anterior&quot;) Figure 3.4: Relação entre chuva atual e o volume de chuva do ano anterior É possível observar que é perfeitamente possível que um ano com um elevado volume de chuvas seja seguido por um ano com baixo volume, e vice-versa. Assim, o volume de chuva que ocorre em um ano não parece explicar muito bem o comportamento da chuva nos anos seguintes. Essa série não parece ter nenhum tipo de tendência, que indicaria que o volume de chuva está aumentando ou diminuindo ao longo do tempo. Não parece existir correlação entre a chuva de um ano e do ano anterior, de modo que podemos ter um ano com um volume muito alto de chuva e no ano seguinte, um volume baixo. De um ponto de vista de modelagem e de previsão, está não é uma série muito interessante. A figura 3.5 mostra uma história diferente. data(hare) hare_df &lt;- data.frame(numero_coelhos = as.matrix(hare), data = time(hare)) hare_df %&gt;% ggplot(aes(x = data, y = numero_coelhos)) + geom_line() + geom_point() + labs(x = &quot;Ano&quot;, y = &quot;Ambundância&quot;, title = &quot;Ambundância de Coelhos Canadenses, 1905-1934&quot;) Figure 3.5: Ambundância de Coelhos Canadenses Diferentemente da série anterior, as observações de um ano estão correlacionadas de maneira muito próxima com aquelas observadas nos anos anteriores. Um número grande em um ano é seguido de um número semelhante no ano seguinte. Vendas de drogas anti-diabetes (figura 3.7) mostram sazonalidade que é induzida por mudanças nos preços dos medicamentos no final do ano calendário. 3.4.2 Sazonalidade A figura 3.6 mostra uma série temporal de temperatura média registrada para uma cidade no estado americano do Iowa. data(tempdub) tempdub &lt;- data.frame(temperatura = as.matrix(tempdub), data = time(tempdub)) tempdub %&gt;% ggplot(aes(x = data, y = temperatura)) + geom_line() + geom_point() + labs(x = &quot;Ano&quot;, y = &quot;Temperatura&quot;, title = &quot;Temperatura Média Mensal no Estado do Iowa, 1964-1976&quot;) Figure 3.6: Temperatura média anual em Iowa Nela observamos uma movimento sazonal muito regular. Um padrão sazonal ocorre quando uma série é afetada por fatores sazonais como o tempo do ano ou o dia da semana. Sazonalidade é sempre uma de uma frequência conhecida e fixa. Sazonalidade para valores mensais ocorre quando observações que são separadas por 12 meses estão relacionados de alguma maneira. Assim, as temperaturas em janeiro de 1910 estão relacionadas com as temperaturas de janeiro de 1911, 1912 e assim por diante. Todos os meses de janeiro e fevereiro são muito frios e são similares em valores de temperatura. Isto não quer dizer que todos os meses de janeiro terão a mesma temperatura, ou os meses de Junho terão sempre a mesma temperatura média. Assim, se quisermos encontrar um modelo para este tipo de série temos que acomodar estas variações mas preservar estas similaridades entre temperaturas dos mesmos meses. a10_df &lt;- data.frame(vendas_drogas = matrix(a10), date = time(a10)) a10_df %&gt;% ggplot(aes(x = date, y = vendas_drogas)) + geom_line() + labs(x = &quot;Ano&quot;, y = &quot;Milhões de US$&quot;, title = &quot;Vendas de Drogas Anti-diabéticos&quot;) Figure 3.7: Vendas de Medicamento contra diabetes A figura 3.8 mostra cada série anual de modo independente. ggseasonplot(a10, year.labels = T, year.labels.left = T) + ylab(&quot;Milhões de US$&quot;) + ggtitle(&quot;Gráfico Sazonal: Vendas de Drogas Anti-diabetes&quot;) Figure 3.8: Gráfico Sazonal de vendas de drogas anti-diabetes A figura permite observar o padrão sazonal com mais clareza, e é especialmente útil para entender o padrão interno dentro de um ano, assim como encontrar anos com mudanças de padrão. Especificamente observamos um aumento significativo da venda de drogas no início do ano. Podemos observar o mesmo gráfico com coordenadas polares. ggseasonplot(a10, polar = T) + ylab(&quot;Milhões de US$&quot;) + ggtitle(&quot;Gráfico Polar Sazonal: \\nVendas de Drogas Anti-diabetes&quot;) Figure 3.9: Gráfico sazonal polar das vendas mensais de medicamentos contra diabetes Outra figura que pode nos ajudar a identificar padrões sazonais é a produzida pela função ggsubseriesplot(). A figura 3.10 mostra um desses exemplos. ggsubseriesplot(a10) + ylab(&quot;Milhões de US$&quot;) + ggtitle(&quot;Sub-séries sazonais para vendas de medicamentos para diabetes&quot;) Figure 3.10: Sub-séries sazonais para vendas de medicamentos para diabetes A linha horizontal mostra a média para cada mês e nos permite enxergar o padrão sazonal com mais clareza. Novamente, ele consegue nos fazer enxergar que o mês de janeiro apresentar uma média muito elevada em comparação aos demais meses do ano. O pacote timetk também oferece uma série de funções para diagnóstico de padrões nas séries temporais. Contudo, o pacote exige que os dados fornecidos estejam no formato de data.frame. library(timetk) a10_df %&gt;% mutate(date = as.Date(date)) %&gt;% plot_seasonal_diagnostics(date, vendas_drogas, .interactive = F) (#fig:seasonal_timetk)Gráfico sazonal das vendas mensais de medicamentos contra diabetes 3.4.3 Tendência A série de vendas de drogas também exibe um padrão de tendência. Uma tendência ocorre quando existe um aumento (ou redução) de longo prazo nos dados. Ela não precisa ser linear, e muitas vezes pode apresentar mudanças de direção, que ocorrem quando uma tendência de aumento se converte em uma tendência de queda. A figura 3.11 mostra outra série com padrão forte de tendência. autoplot(fpp::cafe) + ggtitle(&quot;Gastos Trimestrais com consumo fora do domicílio, Australia&quot;) + xlab(&quot;Ano&quot;) + ylab(&quot;Milhões&quot;) Figure 3.11: Gastos com consumo fora do domicílio na Australia Os gastos dos australianos com consumo fora do domicílio (cafés e restaurantes) tem uma tendência crescente durante todo o período. Ela também exibe um comportamento sazonal dentro de um mesmo ano. 3.4.4 Padrão Cíclico Um comportamento cíclico surge quando os dados exibem um padrão de altas e quedas não possuem frequência fixa. Estas flutuações são os resultados, quase sempre, de condições econômicas, e estão relacionadas ao ciclo de negócios. A duração dessas flutuações tendem a ser de no mínimo 2 anos. A fabricação de equipamentos elétricos na zona do Euro (figura 3.12 exibe um padrão sazonal dentro de cada ano, mas também um forte comportamento cíclico com um período de cerca 5 anos ou mais. autoplot(fpp::elecequip) + ggtitle(&quot;Equipamentos Elétricos Produzidos na Área do Euro&quot;) + xlab(&quot;Ano&quot;) + ylab(&quot;Índice 2005 = 100&quot;) Figure 3.12: Equipamentos elétricos produzidos na zona do Euro Muitas pessoas confundem o comportamento sazonal, mas eles são bem diferentes. Se a flutuação não tem frequência fixa então elas são ciclos; se a frequência não se altera e está associada com algum aspecto do calendario, então o padrão é sazonal. Em geral, o tamanho médio dos ciclos é maior que o comprimento de um padrão sazonal, e a magnitude dos ciclos tende a variar mais do que a magnitude do padrão sazonal. "],["modelos-estatísticos.html", "Capítulo 4 Modelos Estatísticos 4.1 Ruído Branco 4.2 Média Móvel e Filtro 4.3 Autoregressões 4.4 Random Walk com Drift 4.5 Sinal no Ruído", " Capítulo 4 Modelos Estatísticos O objetivo principal da análise de séries temporais é desenvolver modelos matemáticos que ofereçam uma descrição plausível do dado amostral. Nós vamos assumir que uma série temporal pode ser definida como uma coleção de variáveis aleatórias indexadas de acordo com a ordem que elas são obtidas no tempo. Por exemplo, podemos considerar uma série temporal como uma sequência de variáveis aleatórias \\(y_1, y_2, y_3, ...\\), onde a variável aleatória \\(y_1\\) denota o valor tomado de uma série no primeiro período do tempo, a variável \\(y_2\\) denota o valor para o segundo período no tempo, e assim em diante. Em geral, uma coleção de variáveis aleatórias, \\(\\{Y_t\\}\\), indexada por \\(t\\) é referida como um processo estocástico. 4.1 Ruído Branco Ruído branco é um tipo muito simples de série gerada como uma coleção de variáveis aleatoriamente não correlacionadas, \\(w_t\\), com média 0 e variância finita \\(\\sigma^2_w\\). A figura 4.1 mostra uma série desse tipo. ruido_branco = rnorm(200,0,1) df = data.frame(ruido_branco = as.matrix(ruido_branco), x = time(ruido_branco)) df %&gt;% ggplot(aes(x = x, y = ruido_branco)) + geom_line() + labs(x = &quot;Tempo&quot;, y = &quot;y&quot;, title = &quot;Série Temporal do Tipo Ruido Branco&quot;) Figure 4.1: Série Temporal do Tipo Ruído Branco 4.2 Média Móvel e Filtro Podemos substituir a série de ruído branco \\(w_t\\) por uma média móvel que suaviza a série. Por exemplo, considere substituir \\(w_t\\) por uma média dos seus valores atuais e dos seus valores vizinhos no passado e no futuro. Assim, deixe que: \\[v_t = \\frac{1}{3} (w_{t-1} + w_t + w_{t+1})\\] que faz com que a série tenha a aparência mostrada na figura 4.2. df &lt;- df %&gt;% mutate(media_movel = stats::filter(ruido_branco, sides = 2, filter = rep(1/3, 3))) df %&gt;% ggplot(aes(x = x, y = media_movel)) + geom_line() + labs(x = &quot;Tempo&quot;, y = &quot;y&quot;, title = &quot;Série Temporal de Média Móvel&quot;) Figure 4.2: Série temporal de Média Móvel Uma inspeção da série mostra uma versão mais suavizada do gráfico de ruído branco é produzida, refletindo o fato que oscilações grandes são menos aparentes. 4.3 Autoregressões Suponha que consideremos possamos calcular uma série \\(y\\) como uma equação de segunda-ordem da série de ruídos brancos \\(w_t\\): \\[y_t = y_{t-1} - 0.9y_{t-2} + w_t\\] para \\(t=1,2,...,500\\). A equação acima representa uma regressão ou previsão dos valores atuais \\(x_t\\) de uma série temporal como uma função dos dois valores passados da série, e portanto, o termo autoregressivo é sugerido para este modelo. Temos aqui um problema com os valores iniciais da série uma vez que as condições iniciais são importantes (\\(x_0\\) e \\(x_{-1}\\)). Mas, assumindo que temos estes valores, podemos gerar uma sequência de valores apenas substituindo estes valores iniciais na equação acima. O resultado é exibindo na figura 4.3. ruido_branco &lt;- rnorm(250,0,1) # as primeiras 50 observações são excluídas para evitar problemas de startup autoregressivo &lt;- stats::filter(ruido_branco, filter=c(1,-.9), method = &quot;recursive&quot;)[-(1:50)] df &lt;- df %&gt;% mutate(autoregressivo = autoregressivo) df %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = autoregressivo)) + labs(x = &quot;Tempo&quot;, y = &quot;y&quot;, title = &quot;Autogressivo&quot;) Figure 4.3: Série Temporal Autoregressiva O modelo autoregressivo acima mostra um comportamento periódico. O modelo autoregressivo acima e suas generalizações podem ser utilizados como um modelo explicativo para muitos tipos de séries observadas. 4.4 Random Walk com Drift Um modelo para analisar tendências, como as vistas em temperaturas globais, é o random walk com drift. Intuitivamente, em cada período do tempo, a variável toma um passo independente para cima ou para baixo, por isso o termo random walk. A variável vai subir ou descer? A probabilidade dos dois eventos é igual. Uma analogia comumente utilizada é a de um bêbado caminhando em zig-zag pela rua enquanto tenta se mover em frente: o caminho que ele segue é uma caminhada aleatória ou random walk. Assim, o modelo de random walk pode ser definido pela equação: \\[y_t = \\delta + y_{t-1} + w_t\\] para \\(t = 1,2,...,...\\) com condições iniciais \\(y_0 = 0\\) e onde \\(w_t\\)é um ruido branco. A constante \\(\\delta\\) é chamada de drift, e quando \\(\\delta = 0\\), chamamos o modelo simplesmente de random walk. Quando \\(\\delta =0\\), o valor da série em \\(t\\) é o valor da variável no tempo \\(t-1\\) mais um movimento completamente aleatório determinado por \\(w_t\\). Note que podemos reescrever a equação do random walk com drift ao acumular a soma de vários ruídos brancos: \\[x_t = \\delta t + \\sum_{j=1}^t w_t\\] para \\(t = 1,2,...\\). Ou seja, a série é uma soma de passos erráticos. O random walk é um processo que fornece um bom modelo para fenômenos tão diversos quanto preço de ações ou a posição de particulas pequenas suspensas em um flúido (movimento Browniano). A figura 4.4 mostra 500 observações geradas a partir de um modelo com \\(\\delta= 0\\), \\(\\delta = 0.2\\) e \\(\\delta_w = 1\\). set.seed(154) ruido_branco = rnorm(200) random_walk = cumsum(ruido_branco) ruido_branco_drift = ruido_branco + 0.2 random_walk_drift = cumsum(ruido_branco_drift) df &lt;- df %&gt;% mutate(random_walk = random_walk) %&gt;% mutate(random_walk_drift = random_walk_drift) df %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = random_walk, color = &quot;Random Walk&quot;)) + geom_line(aes(y = random_walk_drift, color = &quot;Random Walk com Drift&quot;)) + labs(x = &quot;Tempo&quot;, y = &quot;&quot;, title = &quot;Random Walk&quot;, subtitle = &quot;Random Walk sem Drift e Random Walk com Drift&quot;, color = &quot;Modelo:&quot;) Figure 4.4: Série Temporal com Random Walk 4.5 Sinal no Ruído Muitos modelos realistas para gerar séries temporais assumem um sinal com algum tipo de variação periódica que é contaminada pela adição de um ruído aleatório. Por exemplo, considere um modelo do tipo: \\[y_t = 2 \\cos \\left(2 \\pi \\frac{t + 15}{50}\\right) + w_t\\] para \\(t = 1,2,...,200\\), onde o primeiro termo é o sinal. Abaixo temos um modelo aditivo simples na forma de \\(y_t = s_t + w_t\\), onde \\(s_t\\) denota algum sinal desconhecido e \\(w_t\\) denota um ruído branco. O problema de detectar um sinal e então extrair \\(s_t\\) é de grande interesse. Em economia, o sinal pode ser uma tendência ou um componente sazonal da série. curva_onda = 2*cos(2*pi*1:200/50 + .6*pi) df &lt;- df %&gt;% mutate(curva_onda = curva_onda, curva_onda_ruido = curva_onda + ruido_branco, curva_onda_ruido_forte = curva_onda + 5*ruido_branco) p1 &lt;- df %&gt;% ggplot(aes(x = x, y = curva_onda)) + geom_line() + labs(title = &quot;Curva em Onda&quot;, y = &quot;&quot;, x = &quot;&quot;) p2 &lt;- df %&gt;% ggplot(aes(x = x, y = curva_onda_ruido)) + geom_line() + labs(title = &quot;Curva em Onda + Ruído&quot;, y = &quot;&quot;, x = &quot;&quot;) p3 &lt;- df %&gt;% ggplot(aes(x = x, y = curva_onda_ruido_forte)) + geom_line() + labs(title = &quot;Curva em Onda + Ruído Forte&quot;, y = &quot;&quot;, x = &quot;&quot;) gridExtra::grid.arrange(p1, p2, p3) Figure 4.5: Séries Temporais com diferentes sinais "],["conceitos-básicos.html", "Capítulo 5 Conceitos Básicos 5.1 Média, Variâncias e Covariâncias 5.2 Função Média 5.3 Função de Autocovariância 5.4 A Função de Autocorrelação (FAC)", " Capítulo 5 Conceitos Básicos Aqui vamos descrever alguns conceitos fundamentais sobre a teoria de séries temporais. Em particular, entender o que é um processo estocástico, a média, a função de covariância, processos estocásticos e a função de autocorrelação. 5.1 Média, Variâncias e Covariâncias Agora vamos introduzir várias medidas teoricas utilizadas para descrever como séries temporais se comportam. Como é usual em estatística, a descrição completa da série envolve uma função de distribuição multivariada a amostra conjunta dos valores \\(y_1, y_2, ..., y_n\\), enquanto que uma descrição mais econômica pode ser obtida em termos das funções média e de autocorrelação. Como a correlação é uma característica essencial da análise de séries temporais, as medidas de descrição mais úteis são aquelas expressadas em termos função de autocorrelação e função de autovariância. Vamos discutir alguns conceitos importantes relacionados a todos os tipo de modelos estatísticos de série temporal. Especificamente podemos utilizar algumas medidas para descrever uma série temporal. 5.2 Função Média A função média descreve o valor esperado de uma série temporal. Assim, para um processo estocástico \\(\\{ Y_t\\}\\), a função média é definida como: \\[\\mu_t = E(Y_t)\\] para \\(t = 0,1,2,...\\). Assim, \\(\\mu_t\\) é o valor esperado do processo no tempo \\(t\\). Exemplo 1: Função Média de Média Móvel Para uma media móvel dada por \\(\\frac{1}{3}(w_{t-1} + w_t + w_{t+1})\\), seu valor esperado (função média) é igual a zero, \\(\\mu_y = 0\\). Assim, a função média ao redor de zero descreve bem o comportamento geral da média móvel. O mesmo pode ser dito do ruído branco. df %&gt;% ggplot(aes(x = x, y = ruido_branco)) + geom_line(aes(color = &quot;Ruído Branco&quot;)) + geom_hline(aes(yintercept = 0, color = &quot;Função Média&quot;), linetype = 2, size = 1.5) + labs(x = &quot;Tempo&quot;, y = &quot;&quot;, title = &quot;Média Móvel&quot;, subtitle = &quot;Função Média da Média Móvel é Zero&quot;, color = &quot;&quot;) + theme(legend.position = &quot;bottom&quot;) (#fig:ruido_media)Função Média de um ruído branco Exemplo 2: Função Média de Random Walk com Drift Para um random walk com drift qual a função média? Dado que este modelo é dado por \\(y_t = \\delta t + \\sum_{j=1}^t w_t\\), como \\(E(w_t) = 0\\) e como \\(\\delta\\) é uma constante, temos \\[\\mu(yt) = \\delta t\\] Assim, a função média de uma random walk com drift é uma linha reta com inclinação \\(\\delta\\). Uma comparação de uma random walk com drift e sua função média pode ser vista na figura 5.1. df %&gt;% # criar a função média da random walk mutate(funcao_media_random_walk = .2*x) %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = random_walk_drift, color = &quot;Random Walk com Drift&quot;)) + geom_line(aes(y = funcao_media_random_walk, color = &quot;Função Média&quot;), linetype = 2, size = 1.5) + labs(x = &quot;Tempo&quot;, y = &quot;&quot;, title = &quot;Random Walk com Drift Delta = 0.2&quot;, subtitle = &quot;A função Média é uma linha Reta com Inclinação Delta = 0.2&quot;, color = &quot;Modelo:&quot;) Figure 5.1: Função média de uma série random walk com drift Exemplo 3: Função Média de um Sinal mais Ruído A função média para um modelo aditivo na forma \\(y_t = s_t + w_t\\) é obtido por: \\[\\mu_{yt} = E(y_t) = E[2 \\cos(2\\pi \\frac{2t + 15}{50}) + w_t]\\] Novamente, \\(E(w_t) = 0\\) e os demais termos são constantes, logo: \\[\\mu_{yt} = E(y_t) = 2 \\cos(2\\pi \\frac{2t + 15}{50})\\] A média móvel é apenas o sinal sem o ruído. df %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = curva_onda, color = &quot;Função Média&quot;), size = 1.5, linetype = 2) + geom_line(aes(y = curva_onda_ruido, color = &quot;Sinal com Ruído&quot;)) + labs(title = &quot;Curva em Onda e Sua Função Média&quot;, subtitle = &quot;A função Média é o Sinal sem Ruído&quot;, color = &quot;&quot;) + theme(legend.position = &quot;bottom&quot;) (#fig:sinal_media)Função Média de uma série com sinal 5.3 Função de Autocovariância A função de autocovariância mostra a covariância de um processo consigo mesmo em dois pontos diferentes no tempo. Assim, para uma série mensal de preços, a função de autocovariância mostra a relação entre \\(y_{jan}\\) e \\(y_{fev}\\), que são os valores observados de preço para janeiro e fevereiro, respectivamente. A função de autocovariância \\(\\gamma_{t,s}\\) é definida como: \\[\\gamma_{t,s} = Cov(Y_t, Y_s)\\] para \\(t,s=0,1,2,...\\) Onde \\(Cov(Y_t,Y_s) = E[(Y_t - \\mu_t)(Y_s - \\mu_s)] = E[Y_t Y_s) - \\mu_t \\mu_s\\). Portanto, a autocovariância mede a dependência linear entre dois pontos na mesma série observadas em pontos diferentes. Séries que são muito suavizadas exibem funções de autocovariância que permanecem altas mesmo quando o \\(t\\) e o \\(s\\) estão muito longes entre si. Séries com muita agitação tendem a ter funções de autocovariância que são próximas de zero para valores muito distantes entre si. Lembre que se \\(s = t\\), ou seja, se estivermos comparando uma observação no tempo consigo mesmo, a autovariância se reduz ao valor de variância, porque \\[\\gamma_{y}(t,t) = E[(y_t - \\mu_t)^2] = \\text{Var}(x_t)\\] Exemplo 1: Autocovariância de Ruído Branco Para uma série temporal ruído branco \\(w_t\\) que tem \\(E(w_t)=0\\), temos que \\[\\gamma_w = Cov(w_s, w_t) = 0\\] para \\(s \\neq t\\). Assim, a relação linear entre duas observações é zero. O valor de uma observação num ponto no tempo não influencia em nada os valores observados nos demais pontos do tempo. Exemplo 2: Autocovariância de uma Média Móvel Considere nosso exemplo de uma média móvel. Assim, \\[\\gamma_v (s,t) = cov(v_s, v_t) = cov \\{ \\frac{1}{3}(w_{s-1} + w_s + w_{s+1}), \\frac{1}{3}(w_{t-1} + w_t + w_{t+1}) \\}\\] Quando \\(s = t\\), temos \\[\\gamma_v (s,t) = \\frac{1}{9}cov\\{(w_{t-1} + w_t + w_{t+1}), (w_{t-1} + w_t + w_{t+1}) \\}\\] \\[\\gamma_v (s,t) = \\frac{1}{9}\\[ cov(w_{t-1}, w_{t-1} + cov(w_{t} + w_t) + cov(w_{t+1} + w_{t+1}) \\]\\] \\[\\gamma_v (s,t) = \\frac{3}{9} \\sigma^2_w\\] O mesmo exercício pode ser feito para \\(s = t + 1\\), quando analisamos observações que estão distantes uma observação entre si (janeiro e março, por exemplo), onde \\(\\gamma_v (t + 1, t) = \\frac{2}{9}\\sigma^2_w\\). Quando as observaçãos estão separadas por dois períodos, \\(|s-t| = 2\\), temos \\(\\gamma_v(s,t) = \\frac{1}{9}\\sigma^2_w\\), e quando as observações estão separadas por mais de dois períodos, \\(|s-t| &gt; 2\\), temos \\(\\gamma_v(s,t) = 0\\). Assim, quando suavizamos um ruído branco utilizando uma média móvel, adicionamos um pouco de covariância, mas esta dependência linear se reduz com o aumento da separação entre os valores. Assim, a relação entre janeiro e fevereiro é mais forte que a relação entre janeiro e março. Contudo, a relação entre janeiro e abril seria igual a zero, dado que \\(| \\text{Jan} - \\text{Abr} | &gt; 2\\). Exemplo 3: Autocovariância de um Random Walk Para um modelo random walk, \\(y_t = \\sum_{j = 1}^t w_t\\), temos que \\[\\gamma_y (s,t) = cov(y_s, y_t) = cov \\left( \\sum_{j=1}^2 w_j, \\sum_{k=1}^t w_t\\right) = \\min\\{s,t\\} \\sigma^2_w\\] porque o \\(w_t\\) são variáveis não correlacionadas entre si. Nota que, diferentemente dos exemplos anteriores, a função autocovariância de uma random walk depende no valor em particular de \\(s\\) e \\(t\\), e não na separação entre as observações ou no lag. Perceba também que a variãncia de uma random walk, \\(var(y_t) = t \\sigma^2_w\\), aumenta sem limites quando \\(t\\) cresce. O efeito desta variância pode ser observada na figura para o random walk. Conforme \\(t\\) aumenta, mais e mais a variável se distancia da sua função média \\(\\delta t\\). df %&gt;% # criar a função média da random walk mutate(funcao_media_random_walk = .2*x) %&gt;% ggplot(aes(x = x)) + geom_line(aes(y = random_walk_drift, color = &quot;Random Walk com Drift&quot;)) + geom_line(aes(y = funcao_media_random_walk, color = &quot;Função Média&quot;), linetype = 2, size = 1.5) + labs(x = &quot;Tempo&quot;, y = &quot;&quot;, title = &quot;Random Walk com Drift Delta = 0.2&quot;, subtitle = &quot;Quanto maior o t, maior a distância entre a Série e sua Função Média&quot;, color = &quot;Modelo:&quot;) + theme(legend.position = &quot;bottom&quot;) Figure 5.2: Autocovariância de uma random walk com drift 5.4 A Função de Autocorrelação (FAC) A correlação mensura a relação linear entre duas variáveis. A autocorrelação por sua vez mede a relação linear entre valores defasados ( lagged ) de uma série temporal. Uma forma de mensurar como um valor se relaciona a um valor passado é utilizando a Função de Autocorrelação (FAC), ou ACF em inglês. Ela mede a previsibilidade linear da série no tempo \\(t\\), usando apenas os valores de \\(y_s\\). A função de autocorrelação é definida como \\[\\rho (s,t) = \\frac{\\gamma(s,t)}{\\sqrt{\\gamma(s,s)\\gamma(t,t)}}\\] O valor de \\(\\rho\\), a covariância, esta sempre no intervalo \\([-1,1]\\). Se pudermos prever \\(y_t\\) perfeitamente a partir de \\(y_s\\) através de uma relação linear \\(y_t = \\beta_0 + \\beta_1 y_s\\), então a correlação será \\(+1\\) quando \\(\\beta_1 &gt; 0\\), e a correlação será \\(-1\\) quando \\(\\beta_1 &lt;0\\). Portanto, temos uma medida grosseira da nossa habilidade de prever a série no tempo \\(t\\) utilizando os valores no tempo \\(s\\). Vamos observar esse comportamento na prática utilizando os dados trimestrais de produção de cerveja. A figura 5.3 mostra a série. beer2 &lt;- window(ausbeer, start=1992) autoplot(beer2) + ggtitle(&quot;Produção trimestral de Cerveja, Australia&quot;) + ylab(&quot;&quot;) + xlab(&quot;Ano&quot;) Figure 5.3: Produção trimestral de cerveja É possível observar que os dados possuem um comportamento sazonal bem marcante. Vamos visualizar esse comportamento utilizando o correlograma, o gráfico que nos retorna os coeficientes de autocorrelação. library(forecast) ggAcf(beer2) Figure 5.4: Função de autocorrelação para a produção trimestral de cerveja O gráfico parece mostrar: O \\(r_4\\) é maior que outros lags. Isso é um resultado do padrão sazonal da série. Os picos tendem a ser separados por quatro trimestres e os vales tendem a ser separados por quatro trimestres. \\(r_2\\) é mais negativo que outros lags porque os vales e picos tendem a ser separados por dois trimestres. A linha azul indica se a correlação é significamente diferente de zero. 5.4.1 Tendência e sazonalidade em Correlogramas Quando os dados possuem uma tendência, as autocorrelações para pequenas defasagens é grande e positiva porque as observações próximas no tempo possuem valores semelhantes. Assim, o ACF de uma série com tendência tende a ter valores positivos que lentamente decaem conforme o número de valores defasados (lags) aumenta. A demanda por energia elétrica na australia (figura 5.5) possui um misto de padrão sazonal e tendência. aelec &lt;- window(elec, start=1980) autoplot(aelec) + xlab(&quot;Year&quot;) + ylab(&quot;GWh&quot;) Figure 5.5: Demanda por Energia Elétrica na Australia, 1980-1995 E a função de autocorrelação da série (figura 5.6) tem um decaimento lento devido a tendência, enquanto possui pequenas ondas, que ocorrem devido ao comportamento sazonal da série. ggAcf(aelec, lag=48) Figure 5.6: ACF da demanda australiana por energia elétrica O pacote timetk fornece uma função para gerar o correlograma. aelec_df &lt;- data.frame(electrical_demand = matrix(aelec), date = time(aelec)) %&gt;% mutate(date = as.Date(date)) aelec_df %&gt;% plot_acf_diagnostics(date, electrical_demand, .show_white_noise_bars = T, .interactive = F) ## Max lag exceeds data available. Using max lag: 187 A figura ilustra além do ACF, a função de autocorrelação parcial (PACF, em inglês) que será melhor explicada na seção xxx. 5.4.2 A Função de Covariância-Cruzada e de Correlação-Cruzada De maneira geral, gostariamos de medir a previsibilidade de uma outra série \\(y_t\\) a partir da série \\(x_s\\). Assumindo que ambas as séries tem variância finita, nós temos a seguinte definição para a função de covariância cruzada: \\[\\gamma_{x,y}(s,t) = cov(x_s, y_t) = E[(x_s - \\mu_{xs})]\\] A função de correlação cruzada (FCC) é dada por: \\[\\rho_{xy}(s,t) = \\frac{\\gamma_{xt}(s,t)}{\\sqrt{\\gamma_{x}(s,s) \\gamma_{y}(t,t)}}\\] Podemos inclusive extender a ideia acima para o caso de mais de duas séries. O pacote timetk oferece um banco de dados de vendas semanais na rede walmart. Além de informações de vendas semanais para diferentes departamentos de algumas lojas da Walmart. Além da série de tempo principal, temos algumas covariadas adicionais: isHoliday, que indica se a semana específica possui um feriado, Temperature, que indica a temperatura média da semana e Fuel_Price, que indica o preço do combustível naquela semana. walmart_sales_weekly %&gt;% head() %&gt;% knitr::kable(caption = &quot;Vendas semanais das lojas walmart&quot;) Table 5.1: Vendas semanais das lojas walmart id Store Dept Date Weekly_Sales IsHoliday Type Size Temperature Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 CPI Unemployment 1_1 1 1 2010-02-05 24924.50 FALSE A 151315 42.31 2.572 NA NA NA NA NA 211.0964 8.106 1_1 1 1 2010-02-12 46039.49 TRUE A 151315 38.51 2.548 NA NA NA NA NA 211.2422 8.106 1_1 1 1 2010-02-19 41595.55 FALSE A 151315 39.93 2.514 NA NA NA NA NA 211.2891 8.106 1_1 1 1 2010-02-26 19403.54 FALSE A 151315 46.63 2.561 NA NA NA NA NA 211.3196 8.106 1_1 1 1 2010-03-05 21827.90 FALSE A 151315 46.50 2.625 NA NA NA NA NA 211.3501 8.106 1_1 1 1 2010-03-12 21043.39 FALSE A 151315 57.79 2.667 NA NA NA NA NA 211.3806 8.106 Na figura @ref(fig:walmart_11) exibimos a série de vendas no tempo apenas para o departamento 1 da loja 1. walmart_sales_weekly %&gt;% filter(id == &quot;1_1&quot;) %&gt;% plot_time_series(Date, Weekly_Sales) (#fig:walmart_11)Vendas semanais do Departamento 1 da Loja na Walmart Como temos acesso as covariadas Temperature e Fuel_Price podemos calcular não apenas o ACF, mas também a Função de Correlação-Cruzada com essas duas variáveis. Para tanto, vamos utilizar o parâmetro .ccf_vars na função plot_acf_diagnostics para incluir estas duas variáveis na análise. walmart_sales_weekly %&gt;% group_by(id) %&gt;% select(id, Date, Weekly_Sales, Temperature, Fuel_Price) %&gt;% plot_acf_diagnostics(Date, Weekly_Sales, # Calcular ACF &amp; PACF .ccf_vars = c(Temperature, Fuel_Price), # CCF .lags = &quot;3 months&quot;, .interactive = FALSE) Figure 5.7: Correlação Cruzada de Vendas Semanais com Temperatura e Preço de Combustível A função exibe o ACF e PACF de cada um dos departamentos de cada loja Walmart, além de calcular a correlação cruzada com temperatura e preço de combustíveis. Almas relações curiosas emergem, como a relação entre os valores de vendas semanais e valores passados de temperatura. É possível que essa relação esteja sendo intermediada pelo padrão sazonal de vendas mais fortes no fim do ano. É importante destacar que o padrão da correlação cruzada é afetado pela estrutura das duas séries e a tendência que cada uma tem. É preferível sempre remover a tendência das séries ou levar em consideração a estrutura do ARIMA univariado da variável \\(x\\) antes de aplicar um gráfico de CCF. Esses tópicos serão melhor discutidos na seção xxx e yyy. "],["modelos-de-regressão-dinâmicos.html", "Capítulo 6 Modelos de Regressão Dinâmicos 6.1 Estimação 6.2 Regressão com Erros ARIMA", " Capítulo 6 Modelos de Regressão Dinâmicos O uso de variáveis explicativas exógenas é uma maneira óbvia de melhorar a precisão das precisões. Em vez de depender apenas de informações históricas sobre a série em si, podemos utilizar outras informações relevantes. Modelos de séries temporais como ARIMA permitem que valores da série sejam previstos a partir da inclusão de informações do passado, mas não permitem a inclusão destas variáveis exógenas relevantes como dummies de feriado, atividade dos concorrentes, mudanças nas leis, variáveis macroeconômicas e outras covariadas externas que podem ajudar a explicar a variação histórica de uma série temporal. Já modelos de regressão permitem a inclusão de variáveis externas, mas não são capazes de modelar as dinâmicas presentes em séries temporais, como os modelos ARIMA são capazes. 6.0.1 Valor de utilizar variáveis explicativas Variáveis externas podem ser especialmente úteis para previsão de demanda por eletricidade, que é altamente dependente da temperatura ambiente, uma vez que dias quentes levam a maior uso de ar condicionados (Taieb and Hyndman 2014). Contudo, nem sempre variáveis externas podem ser tão úteis. No caso de temperatura como uma variável explicativa para demanda por eletricidade, as previsões metereológicas podem fornecer medidas bem precisas do comportamento futuro, mas em casos onde as previsões das variáveis explicativas são imprecisas, adiciona-las ao modelo pode produzir resultados inconsistentes. Outro problema pode ocorrer caso a relação entre \\(y\\) e \\(x\\) é um fato histórico, mas pode não se repetir no futuro. Ou quando duas variáveis possuem uma relação positiva em um período, e negativa em outro. Esse tipo de problema pode produzir modelos com má especificações e previsões imprecisas. Assim, antes de recorrer a variáveis externas em modelos de séries temporais, é sempre interessante iniciar a análise com uma abordagem puramente de séries temporais (um modelo ARIMA, por exemplo). Outra estratégia e a de realizar comparações entre (1) uma previsão para dentro da amostra que inclua variáveis explicativas previstas e (2) uma previsão para dentro da amostra que inclua as mesmas variáveis explicativas com dados observados. 6.0.2 Modelos Dinâmicos de Regressão Se existem previsões precisas para as variáveis explicativas e a relação entre estas variáveis e a previsão é estável no futuro, podemos utilizar uma abordagem mista que envolve extender os modelos ARIMA com o objetivo de permitir que outras variáveis externas sejam incluídas nos modelos. Assim, teriamos o melhor dos dois mundos. Estes modelos de regressão simples tomam a forma \\[y_t = \\beta_0 + \\beta_1 x_{1,t} + ... + \\beta_k x_{k,t} + \\epsilon_t\\] onde \\(y_t\\) é uma função linear das \\(k\\) variáveis externas (\\(x_{1,t},...,x_{k,t}\\)), e \\(\\epsilon_t\\) é assumido como um termos de erro não correlacionado (ruído branco). Testes como de Breusch-Godfrey foram utilizados para assegurar que os resíduos resultantes da regressão eram significativamente correlacionados. Neste capítulo, os erros da regressão podem conter autocorrelação. Para enfatizar esta mudança, vamos substituir o uso do \\(\\epsilon_t\\) por \\(\\eta_t\\). A série de erros \\(\\eta_t\\) é assumido como um processo ARIMA. Por exemplo, se \\(\\eta_t\\) seguir um processo ARIMA(1,1,1), podemos escrever o modelo como \\[y_t = \\beta_0 + \\beta_1 x_{1,t} + ... + \\beta_k x_{k,t} + \\eta_t\\] \\[(1-\\Phi_1 B)(1-B)\\eta_t = (1+ \\theta_1 B) \\epsilon_t\\] onde \\(\\epsilon_t\\) é a série de ruído branco. Note que o modelo tem dois termos de erro - o erro do modelo de regressão, que denotamos como \\(\\eta_\\). e o termo de erro do modelo ARIMA, que denotamos como \\(\\epsilon_t\\). Apenas os erros do modelo ARIMA são assumidos como ruído branco. 6.1 Estimação Quando estimamos parâmetros do modelo, minimizamos a soma de \\(\\epsilon_t\\) ao quadrado. Se minimizarmos a soma de \\(\\eta_t\\) ao quadrado (que é o que ocorre quando estimamos um modelo de regressão que ignora a autocorrelação dos erros), então uma série de problemas surgem. Os coeficientes estimados \\(\\hat{\\beta}_0,...,\\hat{\\beta}_k\\) não são mais os melhores estimadores, já que algumas informações importantes estão sendo ignoradas no cálculo dos coeficientes. Qualquer teste estatístico associado com o modelo será incorreto. Os valores de AIC dos modelos ajustados não são um bom guia de quão bom é o modelo para previsão. Na maioria dos casos, o p-valor associado com os coeficientes será muito pequeno, e algumas covariadas parecerão importantes quando na verdade não são. Isto produzirá uma regressão espúria. Minimizar a soma dos \\(\\epsilon_t\\) ao quadrado evita estes problemas. Alternativamente, estimação por máxima verossimilhança pode ser utilizada, produzindo estimativas de coeficientes similares. Uma importante consideração quando estimando um modelo de regressão com erros ARMA é de que todas as variáveis do modelo devem ser estacionárias. Portanto, devemos primeiro checar se \\(y_t\\) é todas as covariadas são estacionárias. Se estimarmos o modelo quando qualquer uma delas é não-estacionária, os coeficientes produzidos não serão consistentes. Uma exceção é quando variáveis não-estacionárias são cointegradas. Se existe uma combinação linear de \\(y_t\\) não-estacionário com um \\(x_t\\) estacionário, então o coeficiente é consistente. Para tornar as variáveis estacionárias, podemos realizar a transformação de diferenciação, o que produz o chamado modelo em diferença, em contraste com o modelo em nível, em os dados originais são utilizados. Se todas as variáveis são estacionárias, então podemos utilizar erros ARMA para os resíduos. É fácil notar que uma regressão com erros ARIMA é equivalente a uma regressão em diferença com erros ARMA. 6.2 Regressão com Erros ARIMA A função Arima() é capaz de ajustar um modelo de regressão com erros ARIMA se o argumento xreg for utilizado. Como diferenciação está especificada, a diferenciação é aplicada para todas as variáveis antes de estimar o modelo. O comando R utilizado é library(forecast) Arima(y, xreg = x, order = c(1,1,0)) que irá ajustar um modelo do tipo \\(y&#39;_t = \\beta_1 x&#39;_t + \\eta&#39;_t\\). A função auto.arima() também é capaz de utilizar covariadas com uso do termo xreg. O usuário deve especificar os preditores e auto.arima() seleciona o melhor modelo ARIMA para os erros. 6.2.1 Exemplo: Consumo e Renda nos EUA A figura 6.1 mostra a mudança trimestral nos gastos com consumo pessoal e a renda disponível entre 1970 e 2016. Estamos interessados em prever o consumo com base na renda. Uma mudança na renda não necessariamente reflete uma mudança instântanea no consumo (exempl, depois de uma demissão, pode levar alguns meses para os gastos se ajustarem). Contudo, vamos ignorar esta complexidade e tentar medir o efeito instantâneo de uma mudança média na renda sore uma mudança média nos gastos. library(fpp) autoplot(usconsumption, facets = TRUE) + xlab(&quot;Ano&quot;) + ylab(&quot;&quot;) + ggtitle(&quot;Mudança Trimestral no Consumo e Renda, EUA&quot;) Figure 6.1: Mudança Percental no Consumo e Renda Trimestral para os EUA, 1970 a 2010 fit &lt;- auto.arima(usconsumption[,&quot;consumption&quot;], xreg=usconsumption[,&quot;income&quot;]) fit ## Series: usconsumption[, &quot;consumption&quot;] ## Regression with ARIMA(1,0,2) errors ## ## Coefficients: ## ar1 ma1 ma2 intercept xreg ## 0.6516 -0.5440 0.2187 0.5750 0.2420 ## s.e. 0.1468 0.1576 0.0790 0.0951 0.0513 ## ## sigma^2 estimated as 0.3502: log likelihood=-144.27 ## AIC=300.54 AICc=301.08 BIC=319.14 Os dados são claramente estacionários (já que estamos considerando mudanças percentuais em vez de gastos e renda bruta), de modo que não há necessidade de diferenciação. O modelo ajustado é \\[y_t = 0.5750 + 0.2420x_t + \\eta_t\\] \\[\\eta_t = 0.6516 \\eta_{t-1} + \\epsilon_t - 0.5440 + 0.218 \\epsilon_t\\] \\[\\epsilon ~ IID(0, 0.3502\\] Podemos recuperar as estimativas de \\(\\eta_t\\) e \\(\\epsilon_t\\) usando a função residuals(). cbind(&quot;Erros de Regressão&quot; = residuals(fit, type=&quot;regression&quot;), &quot;Erros ARIMA&quot; = residuals(fit, type=&quot;innovation&quot;)) %&gt;% autoplot(facets=T) Figure 6.2: Resíduos de Regressão e Resíduos ARIMA para o modelo ajustado O teste de Ljung-Box, ACF e histograma parecem indicar que os resíduos não são significativamente diferentes de um ruído branco. checkresiduals(fit) ## ## Ljung-Box test ## ## data: Residuals from Regression with ARIMA(1,0,2) errors ## Q* = 4.455, df = 3, p-value = 0.2163 ## ## Model df: 5. Total lags used: 8 References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
